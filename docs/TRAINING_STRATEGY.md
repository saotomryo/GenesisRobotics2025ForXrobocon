# XROBOCON 訓練戦略

## 目標
低レベル制御AI: 「指定された相対位置に移動する」能力を訓練
高レベル戦略AI: Geminiが経路計画を担当（Phase 4）

## Phase 1: 地面での基本移動（現在）

### 訓練シナリオ
1. **短距離直進** (0.5m)
   - 開始: (0, -0.5, 0.05), Yaw=90°
   - 目標: (0, 0, 0.05)
   - 目的: 基本的な直進制御

2. **中距離直進** (1.0m)
   - 開始: (0, -1.0, 0.05), Yaw=90°
   - 目標: (0, 0, 0.05)
   - 目的: 長距離での安定性

3. **長距離直進** (2.0m)
   - 開始: (0, -2.0, 0.05), Yaw=90°
   - 目標: (0, 0, 0.05)
   - 目的: 長距離ナビゲーション

4. **斜め移動** (1.0m, 45°)
   - 開始: (-0.7, -0.7, 0.05), Yaw=45°
   - 目標: (0, 0, 0.05)
   - 目的: 斜め方向への移動

5. **横移動** (1.0m, 90°回転必要)
   - 開始: (-1.0, 0, 0.05), Yaw=90°
   - 目標: (0, 0, 0.05)
   - 目的: 回転してから移動

### 観測空間（15次元）
- ロボット位置 (x, y, z): 3次元
- ロボット姿勢 (roll, pitch, yaw): 3次元
- 線形速度 (vx, vy, vz): 3次元
- 角速度 (wx, wy, wz): 3次元
- **ターゲットベクトル (dx, dy, dz): 3次元** ← 目標への相対位置

### 報酬関数
- ターゲット接近: (prev_dist - current_dist) × 20.0
- ターゲット到達: +50.0 (0.3m以内)
- 安定性: -|roll| × 0.01 - |pitch| × 0.01
- 転倒: -100.0 (終了)
- 落下: -100.0 (終了)

### 期待される学習
- 10,000ステップ: 短距離直進が可能
- 50,000ステップ: 中距離直進、基本的な回転
- 100,000ステップ: 全シナリオで50%以上の成功率

## Phase 2: スロープ登坂（次のステップ）

### 訓練シナリオ
1. **Ramp 1登坂**
   - 開始: (1.5, -1.5, 0.05) - Ramp 1手前
   - 目標: (1.5, 0.0, 0.1) - Ramp 1頂上

2. **Ramp 2登坂**
   - 開始: Tier 1上、Ramp 2手前
   - 目標: Ramp 2頂上

3. **Ramp 3登坂**
   - 開始: Tier 2上、Ramp 3手前
   - 目標: Ramp 3頂上

## Phase 3: フィールド上移動（その次）

### 訓練シナリオ
1. **Tier 1上の移動**
   - コイン間の移動（全パターン）
   
2. **Tier 2上の移動**
   - コイン間の移動

3. **Tier 3上の移動**
   - コイン間の移動

## Phase 4: Gemini統合（最終）

### 統合方法
1. Geminiがカメラ画像を見て戦略立案
2. Geminiが次の目標位置を指定: `env.set_target((x, y, z))`
3. RLエージェントが目標に移動
4. 到達後、Geminiが次の目標を指定
5. 繰り返し

### 例
```python
# Gemini: "まずRamp 1を登ろう"
env.set_target((1.5, 0.0, 0.1))
# RL: 移動実行

# Gemini: "次は近くのコインを取ろう"
env.set_target((1.0, 0.8, 0.1))
# RL: 移動実行
```

## 訓練の進め方

### Step 1: 基本移動の習得（現在）
```bash
rm xrobocon_ppo.zip  # 既存モデル削除
python train_rl.py --train --steps 100000
python evaluate_model.py --episodes 20
```

期待結果: 成功率 50%以上

### Step 2: スロープ追加
`env.py`のシナリオにスロープを追加して再訓練

### Step 3: フィールド移動追加
コイン間移動シナリオを追加

### Step 4: Gemini統合
`plan_gemini.py`を実装
